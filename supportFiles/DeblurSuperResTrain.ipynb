{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-z-XHs3KNbS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Conv2D, BatchNormalization, Input, Layer, InputSpec, Add, Dropout, Lambda, UpSampling2D, Flatten, Dense, LeakyReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tqdm\n",
        "import datetime\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from sklearn.utils import shuffle\n",
        "from imutils import build_montages\n",
        "import torch\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "\n",
        "    def __init__(self, padding=(1, 1), data_format=None, **kwargs):\n",
        "\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = tuple((padding, padding))\n",
        "        else:\n",
        "            self.padding = tuple(padding)\n",
        "        if data_format is None:\n",
        "            value = K.image_data_format()\n",
        "        self.data_format = value.lower()\n",
        "        self.input_spec = [InputSpec(ndim=4)]\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, s):\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            return s[0], s[1], s[2] + 2 * self.padding[0], s[3] + 2 * self.padding[1]\n",
        "        elif self.data_format == 'channels_last':\n",
        "            return s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3]\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        w_pad, h_pad = self.padding\n",
        "        if self.data_format == 'channels_first':\n",
        "            pattern = [[0, 0], [0, 0], [h_pad, h_pad], [w_pad, w_pad]]\n",
        "        elif self.data_format == 'channels_last':\n",
        "            pattern = [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]]\n",
        "\n",
        "        return tf.pad(x, pattern, 'REFLECT')\n",
        "\n",
        "\n",
        "def ResBlock(input, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
        "    x = ReflectionPadding2D((1, 1))(input)\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = ReflectionPadding2D((1, 1))(x)\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    out = Add()([input, x])\n",
        "    return out\n",
        "\n",
        "class DCGAN:\n",
        "\n",
        "    @staticmethod\n",
        "    def build_generator(image_shape, num_gen_filter, num_resblock):\n",
        "\n",
        "        inputs = Input(shape=image_shape)\n",
        "\n",
        "        x = ReflectionPadding2D((3, 3))(inputs)\n",
        "        x = Conv2D(filters=num_gen_filter, kernel_size=(7, 7), padding='valid')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        n_downsample = 2\n",
        "        for i in range(n_downsample):\n",
        "            mul = 2**i\n",
        "            x = Conv2D(filters=num_gen_filter * mul * 2, kernel_size=(3, 3), strides=2, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "        \n",
        "        x = Conv2D(filters=num_gen_filter * 8, kernel_size=(1, 1), strides=2, padding='same')(x)\n",
        "\n",
        "        mul = 2**n_downsample\n",
        "        for i in range(num_resblock):\n",
        "            x = ResBlock(x, num_gen_filter * mul * 2)\n",
        "\n",
        "        n_upsample = 4\n",
        "        for i in range(n_upsample):\n",
        "            mul = 2**(n_upsample - i)\n",
        "            x = UpSampling2D()(x)\n",
        "            x = Conv2D(filters=int(num_gen_filter * mul / 2), kernel_size=(3, 3), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "\n",
        "        x = ReflectionPadding2D((3, 3))(x)\n",
        "        x = Conv2D(filters=3, kernel_size=(7, 7), padding='valid')(x)\n",
        "        x = Activation('tanh')(x)\n",
        "\n",
        "        outputs = Add()([x, UpSampling2D()(inputs)])\n",
        "        outputs = Lambda(lambda z: z/2)(outputs)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=x, name='Generator')\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_discriminator(image_shape, num_dis_filter):\n",
        "\n",
        "        n_layers = 3\n",
        "        inputs = Input(shape=image_shape)\n",
        "\n",
        "        x = Conv2D(filters=num_dis_filter, kernel_size=(4, 4), strides=2, padding='same')(inputs)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        nf_mult, nf_mult_prev = 1, 1\n",
        "        for n in range(n_layers):\n",
        "            nf_mult_prev, nf_mult = nf_mult, min(2**n, 8)\n",
        "            x = Conv2D(filters=num_dis_filter * nf_mult, kernel_size=(4, 4), strides=2, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        nf_mult_prev, nf_mult = nf_mult, min(2**n_layers, 8)\n",
        "        x = Conv2D(filters=num_dis_filter * nf_mult, kernel_size=(4, 4), strides=1, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "        x = Conv2D(filters=1, kernel_size=(4, 4), strides=1, padding='same')(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(1024, activation='tanh')(x)\n",
        "        x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=x, name='Discriminator')\n",
        "        return model"
      ],
      "metadata": {
        "id": "w82IlAaC2_zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptual_loss(y_true, y_pred):\n",
        "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=(64, 64, 3))\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    loss_model.trainable = False\n",
        "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return K.mean(y_true*y_pred)"
      ],
      "metadata": {
        "id": "TZSGlBvn28eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurImages = (torch.load('path to train blurimages').numpy() - 127.5 ) / 127.5\n",
        "sharpImages = (torch.load('path to train sharpimages').numpy() - 127.5) / 127.5\n",
        "bt = (torch.load('path to test blurimages').numpy() - 127.5 ) / 127.5\n",
        "st = torch.load('path to test sharpimages').numpy()"
      ],
      "metadata": {
        "id": "NQRqrwBr4xSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num = 5\n",
        "batch_size = 64\n",
        "\n",
        "shape = (256, 256, 3)\n",
        "\n",
        "y_train, x_train = shuffle(sharpImages), shuffle(blurImages)\n",
        "\n",
        "gen = DCGAN.build_generator(shape, 64, 9)\n",
        "dis = DCGAN.build_discriminator((512, 512, 3), 64)\n",
        "inputs = Input(shape=shape)\n",
        "gen_image = gen(inputs)\n",
        "outputs = dis(gen_image)\n",
        "dis_on_gen = Model(inputs=inputs, outputs=[gen_image, outputs])\n",
        "\n",
        "dis_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "dis_on_gen_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "dis.trainable = True\n",
        "dis.compile(optimizer=dis_opt, loss=wasserstein_loss)\n",
        "dis.trainable = False\n",
        "loss = [perceptual_loss, wasserstein_loss]\n",
        "loss_weights = [100, 1]\n",
        "dis_on_gen.compile(optimizer=dis_on_gen_opt, loss=loss, loss_weights=loss_weights)\n",
        "dis.trainable = True\n",
        "\n",
        "output_true_batch, output_false_batch = np.ones((batch_size, 1)), -np.ones((batch_size, 1))\n",
        "\n",
        "for epoch in tqdm.tqdm(range(epoch_num)):\n",
        "\n",
        "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1, epoch_num))\n",
        "\n",
        "    dis_losses = []\n",
        "    dis_on_gen_losses = []\n",
        "    batchesPerEpoch = int(blurImages.shape[0] / batch_size)\n",
        "    x_train = shuffle(x_train)\n",
        "    y_train = shuffle(y_train)\n",
        "\n",
        "    for i in range(batchesPerEpoch):\n",
        "\n",
        "        image_blur_batch = x_train[i * batch_size:(i + 1) * batch_size]\n",
        "        image_sharp_batch = y_train[i * batch_size:(i + 1) * batch_size]\n",
        "\n",
        "        generated_images = gen.predict(x=image_blur_batch, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        for _ in range(5):\n",
        "            dis_loss_real = dis.train_on_batch(image_sharp_batch, output_true_batch)\n",
        "            dis_loss_fake = dis.train_on_batch(generated_images, output_false_batch)\n",
        "            dis_loss = 0.5 * np.add(dis_loss_fake, dis_loss_real)\n",
        "            dis_losses.append(dis_loss)\n",
        "\n",
        "        dis.trainable = False\n",
        "\n",
        "        dis_on_gen_loss = dis_on_gen.train_on_batch(image_blur_batch, [image_sharp_batch, output_true_batch])\n",
        "        dis_on_gen_losses.append(dis_on_gen_loss)\n",
        "\n",
        "        dis.trainable = True\n",
        "        print(\"[INFO] Epoch: %d, Step: %d, discriminator_loss: %.6f, adversarial_loss: %.6f\" % (epoch + 1, i, dis_loss, np.mean(dis_on_gen_loss)))\n",
        "\n",
        "    print(np.mean(dis_losses), np.mean(dis_on_gen_losses))\n",
        "    with open('log.txt', 'a+') as f:\n",
        "        f.write(\n",
        "            'Epoch {} - Discriminator Loss {} - GaN Loss {}\\n'.format(epoch, np.mean(dis_losses),\n",
        "                                                                      np.mean(dis_on_gen_losses)))"
      ],
      "metadata": {
        "id": "_t0a4e-aKY-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = gen.predict(bt, verbose=0)\n",
        "pred = (pred * 127.5) + 127.5"
      ],
      "metadata": {
        "id": "L6P92vPlKd6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = []\n",
        "pp = []\n",
        "for i in range(len(pred)):\n",
        "    ss.append(ssim(pred[i], st[i], multichannel=True))\n",
        "    pp.append(psnr(pred[i], st[i], data_range=255))\n",
        "\n",
        "ss = np.array(ss)\n",
        "print(np.mean(ss))\n",
        "\n",
        "pp = np.array(pp)\n",
        "print(np.mean(pp))"
      ],
      "metadata": {
        "id": "7tPgPWBvPGMk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}